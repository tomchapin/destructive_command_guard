name: ci

on:
  pull_request:
  push:
    branches: [master, main]

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1

jobs:
  check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: dtolnay/rust-toolchain@nightly
        with:
          components: rustfmt, clippy

      - name: Install cargo-nextest
        uses: taiki-e/install-action@nextest

      - name: Cache cargo registry and target
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock', '**/Cargo.toml') }}
          restore-keys: |
            ${{ runner.os }}-cargo-

      - name: Check formatting
        run: cargo fmt -- --check

      - name: Run clippy
        run: cargo clippy --all-targets -- -D warnings

      - name: Check compilation
        run: cargo check --all-targets

      - name: Run tests (with JUnit XML report)
        run: |
          cargo nextest run --profile ci --no-fail-fast

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-check
          path: target/nextest/ci/junit.xml
          retention-days: 14
          if-no-files-found: ignore

      - name: Test Report Summary
        if: always()
        uses: dorny/test-reporter@v1
        with:
          name: Unit Tests
          path: target/nextest/ci/junit.xml
          reporter: java-junit
          fail-on-error: false

  coverage:
    runs-on: ubuntu-latest
    needs: check
    steps:
      - uses: actions/checkout@v4

      - uses: dtolnay/rust-toolchain@nightly
        with:
          components: llvm-tools-preview

      - name: Install cargo-llvm-cov
        uses: taiki-e/install-action@cargo-llvm-cov

      - name: Cache cargo registry and target
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ runner.os }}-cargo-cov-${{ hashFiles('**/Cargo.lock', '**/Cargo.toml') }}
          restore-keys: |
            ${{ runner.os }}-cargo-cov-

      - name: Run tests with coverage
        run: |
          cargo llvm-cov --all-features --workspace \
            --ignore-filename-regex='(tests/|benches/|\.cargo/)' \
            --no-report

      - name: Generate coverage reports
        run: |
          # Generate LCOV from collected data (no re-running tests)
          cargo llvm-cov report --all-features --workspace \
            --ignore-filename-regex='(tests/|benches/|\.cargo/)' \
            --lcov --output-path lcov.info
          # Generate text summary from collected data
          cargo llvm-cov report --all-features --workspace \
            --ignore-filename-regex='(tests/|benches/|\.cargo/)' \
            --text > coverage-summary.txt
          echo "## Coverage Summary" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          tail -20 coverage-summary.txt >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

      - name: Upload coverage artifact
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: |
            lcov.info
            coverage-summary.txt
          retention-days: 30

      - name: Check coverage thresholds (enforced)
        run: |
          set -euo pipefail

          OVERALL_MIN="70.0"
          EVALUATOR_MIN="80.0"
          HOOK_MIN="80.0"

          overall=$(grep 'TOTAL' coverage-summary.txt | grep -Eo '[0-9]+\.[0-9]+%' | tail -1 | tr -d '%' || echo "")
          evaluator=$(awk '$1 ~ /src\/evaluator\.rs$/ {print $2}' coverage-summary.txt | tr -d '%' | tail -1 || true)
          hook=$(awk '$1 ~ /src\/hook\.rs$/ {print $2}' coverage-summary.txt | tr -d '%' | tail -1 || true)

          echo "Coverage thresholds:"
          echo "  overall >= ${OVERALL_MIN}%"
          echo "  src/evaluator.rs >= ${EVALUATOR_MIN}%"
          echo "  src/hook.rs >= ${HOOK_MIN}%"
          echo ""
          echo "Observed coverage:"
          echo "  overall=${overall}%"
          echo "  src/evaluator.rs=${evaluator}%"
          echo "  src/hook.rs=${hook}%"

          echo "coverage_overall=${overall}" >> "$GITHUB_OUTPUT"
          echo "coverage_evaluator=${evaluator}" >> "$GITHUB_OUTPUT"
          echo "coverage_hook=${hook}" >> "$GITHUB_OUTPUT"

          failures=0
          if [ -z "$overall" ]; then
            echo "::error::Failed to parse TOTAL coverage from coverage-summary.txt"
            failures=$((failures + 1))
          elif [ "$(echo "$overall < $OVERALL_MIN" | bc -l)" -eq 1 ]; then
            echo "::error::Overall coverage ${overall}% is below ${OVERALL_MIN}%"
            failures=$((failures + 1))
          fi

          if [ -z "$evaluator" ]; then
            echo "::error::Failed to parse src/evaluator.rs coverage from coverage-summary.txt"
            failures=$((failures + 1))
          elif [ "$(echo "$evaluator < $EVALUATOR_MIN" | bc -l)" -eq 1 ]; then
            echo "::error::src/evaluator.rs coverage ${evaluator}% is below ${EVALUATOR_MIN}%"
            failures=$((failures + 1))
          fi

          if [ -z "$hook" ]; then
            echo "::error::Failed to parse src/hook.rs coverage from coverage-summary.txt"
            failures=$((failures + 1))
          elif [ "$(echo "$hook < $HOOK_MIN" | bc -l)" -eq 1 ]; then
            echo "::error::src/hook.rs coverage ${hook}% is below ${HOOK_MIN}%"
            failures=$((failures + 1))
          fi

          if [ "$failures" -gt 0 ]; then
            echo "::error::Coverage thresholds not met (${failures} failure(s))"
            exit 1
          fi

          echo "Coverage thresholds satisfied."

  # Performance benchmark enforcement (push to master only)
  # Runs benchmarks and checks against performance budgets defined in src/perf.rs
  benchmarks:
    runs-on: ubuntu-latest
    needs: check
    # Only run on push to master/main, not on PRs (benchmarks are noisy)
    if: github.event_name == 'push' && (github.ref == 'refs/heads/master' || github.ref == 'refs/heads/main')
    steps:
      - uses: actions/checkout@v4

      - uses: dtolnay/rust-toolchain@nightly

      - name: Cache cargo registry and target
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ runner.os }}-cargo-bench-${{ hashFiles('**/Cargo.lock', '**/Cargo.toml') }}
          restore-keys: |
            ${{ runner.os }}-cargo-bench-

      - name: Run benchmarks
        run: |
          # Run benchmarks and capture output
          cargo bench --bench heredoc_perf -- --noplot 2>&1 | tee benchmark_output.txt
          echo "## Benchmark Results" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          grep -E "^(tier|pack|core|shell|language|full)" benchmark_output.txt | head -50 >> $GITHUB_STEP_SUMMARY || true
          echo '```' >> $GITHUB_STEP_SUMMARY

      - name: Check performance budgets
        run: |
          # Extract timing summaries and check against budgets
          # Budgets from src/perf.rs:
          # - Quick reject: 50μs panic
          # - Fast path: 500μs panic
          # - Pattern match: 1ms panic
          # - Heredoc extract: 2ms panic
          # - Full pipeline: 50ms panic
          echo "## Performance Budget Check" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          PANIC_VIOLATIONS=0

          # Check for any results exceeding 50ms (absolute max)
          if grep -E "time:.*\[.*[0-9]+\.[0-9]+ s" benchmark_output.txt; then
            echo "::error::Some benchmarks exceeded 1 second - major regression detected"
            PANIC_VIOLATIONS=$((PANIC_VIOLATIONS + 1))
          fi

          # Check full_pipeline benchmarks (budget: 50ms panic)
          if grep -A1 "full_pipeline" benchmark_output.txt | grep -E "time:.*\[.*[5-9][0-9]\.[0-9]+ ms|[0-9]{3,}\.[0-9]+ ms"; then
            echo "::warning::Full pipeline benchmark exceeds 50ms budget"
            PANIC_VIOLATIONS=$((PANIC_VIOLATIONS + 1))
          fi

          if [ $PANIC_VIOLATIONS -gt 0 ]; then
            echo "::error::$PANIC_VIOLATIONS performance budget violations detected"
            echo "Budget violations: $PANIC_VIOLATIONS" >> $GITHUB_STEP_SUMMARY
            # For now, warn but don't fail (benchmarks can be noisy in CI)
            # exit 1
          else
            echo "All benchmarks within budget" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: benchmark_output.txt
          retention-days: 30
